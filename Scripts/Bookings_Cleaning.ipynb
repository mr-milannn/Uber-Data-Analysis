{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ede5aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f350828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "Index(['Date', 'Time', 'Booking ID', 'Booking Status', 'Customer ID',\n",
      "       'Vehicle Type', 'Pickup Location', 'Drop Location', 'Avg VTAT',\n",
      "       'Avg CTAT', 'Cancelled Rides by Customer',\n",
      "       'Reason for cancelling by Customer', 'Cancelled Rides by Driver',\n",
      "       'Driver Cancellation Reason', 'Incomplete Rides',\n",
      "       'Incomplete Rides Reason', 'Booking Value', 'Ride Distance',\n",
      "       'Driver Ratings', 'Customer Rating', 'Payment Method'],\n",
      "      dtype='object')\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 21 columns):\n",
      " #   Column                             Non-Null Count   Dtype  \n",
      "---  ------                             --------------   -----  \n",
      " 0   Date                               150000 non-null  object \n",
      " 1   Time                               150000 non-null  object \n",
      " 2   Booking ID                         150000 non-null  object \n",
      " 3   Booking Status                     150000 non-null  object \n",
      " 4   Customer ID                        150000 non-null  object \n",
      " 5   Vehicle Type                       150000 non-null  object \n",
      " 6   Pickup Location                    150000 non-null  object \n",
      " 7   Drop Location                      150000 non-null  object \n",
      " 8   Avg VTAT                           139500 non-null  float64\n",
      " 9   Avg CTAT                           102000 non-null  float64\n",
      " 10  Cancelled Rides by Customer        10500 non-null   float64\n",
      " 11  Reason for cancelling by Customer  10500 non-null   object \n",
      " 12  Cancelled Rides by Driver          27000 non-null   float64\n",
      " 13  Driver Cancellation Reason         27000 non-null   object \n",
      " 14  Incomplete Rides                   9000 non-null    float64\n",
      " 15  Incomplete Rides Reason            9000 non-null    object \n",
      " 16  Booking Value                      102000 non-null  float64\n",
      " 17  Ride Distance                      102000 non-null  float64\n",
      " 18  Driver Ratings                     93000 non-null   float64\n",
      " 19  Customer Rating                    93000 non-null   float64\n",
      " 20  Payment Method                     102000 non-null  object \n",
      "dtypes: float64(9), object(12)\n",
      "memory usage: 24.0+ MB\n",
      "=========================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg VTAT</th>\n",
       "      <th>Avg CTAT</th>\n",
       "      <th>Cancelled Rides by Customer</th>\n",
       "      <th>Cancelled Rides by Driver</th>\n",
       "      <th>Incomplete Rides</th>\n",
       "      <th>Booking Value</th>\n",
       "      <th>Ride Distance</th>\n",
       "      <th>Driver Ratings</th>\n",
       "      <th>Customer Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>139500.000000</td>\n",
       "      <td>102000.000000</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>27000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>102000.000000</td>\n",
       "      <td>102000.000000</td>\n",
       "      <td>93000.000000</td>\n",
       "      <td>93000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.456352</td>\n",
       "      <td>29.149636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>508.295912</td>\n",
       "      <td>24.637012</td>\n",
       "      <td>4.230992</td>\n",
       "      <td>4.404584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.773564</td>\n",
       "      <td>8.902577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>395.805774</td>\n",
       "      <td>14.002138</td>\n",
       "      <td>0.436871</td>\n",
       "      <td>0.437819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.300000</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>12.460000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>4.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.300000</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>414.000000</td>\n",
       "      <td>23.720000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.300000</td>\n",
       "      <td>36.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>689.000000</td>\n",
       "      <td>36.820000</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4277.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Avg VTAT       Avg CTAT  Cancelled Rides by Customer  \\\n",
       "count  139500.000000  102000.000000                      10500.0   \n",
       "mean        8.456352      29.149636                          1.0   \n",
       "std         3.773564       8.902577                          0.0   \n",
       "min         2.000000      10.000000                          1.0   \n",
       "25%         5.300000      21.600000                          1.0   \n",
       "50%         8.300000      28.800000                          1.0   \n",
       "75%        11.300000      36.800000                          1.0   \n",
       "max        20.000000      45.000000                          1.0   \n",
       "\n",
       "       Cancelled Rides by Driver  Incomplete Rides  Booking Value  \\\n",
       "count                    27000.0            9000.0  102000.000000   \n",
       "mean                         1.0               1.0     508.295912   \n",
       "std                          0.0               0.0     395.805774   \n",
       "min                          1.0               1.0      50.000000   \n",
       "25%                          1.0               1.0     234.000000   \n",
       "50%                          1.0               1.0     414.000000   \n",
       "75%                          1.0               1.0     689.000000   \n",
       "max                          1.0               1.0    4277.000000   \n",
       "\n",
       "       Ride Distance  Driver Ratings  Customer Rating  \n",
       "count  102000.000000    93000.000000     93000.000000  \n",
       "mean       24.637012        4.230992         4.404584  \n",
       "std        14.002138        0.436871         0.437819  \n",
       "min         1.000000        3.000000         3.000000  \n",
       "25%        12.460000        4.100000         4.200000  \n",
       "50%        23.720000        4.300000         4.500000  \n",
       "75%        36.820000        4.600000         4.800000  \n",
       "max        50.000000        5.000000         5.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = r'D:\\Projects\\PowerBi Projects\\Uber\\ncr_ride_bookings.csv'\n",
    "df=pd.read_csv(file)\n",
    "print(\"=======\"*15)\n",
    "print(df.columns)\n",
    "print(\"=======\"*15)\n",
    "df.head()\n",
    "print(\"=======\"*15)\n",
    "df.info()\n",
    "print(\"=======\"*15)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7dfab662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "2. Initial Column Name Clean-up\n",
      "=========================================================================================================\n",
      "Initial columns: ['date', 'time', 'booking_id', 'booking_status', 'customer_id', 'vehicle_type', 'pickup_location', 'drop_location', 'avg_vtat', 'avg_ctat', 'cancelled_rides_by_customer', 'reason_for_cancelling_by_customer', 'cancelled_rides_by_driver', 'driver_cancellation_reason', 'incomplete_rides', 'incomplete_rides_reason', 'booking_value', 'ride_distance', 'driver_ratings', 'customer_rating', 'payment_method']\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"2. Initial Column Name Clean-up\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '_').str.replace('[^A-Za-z0-9_]+', '', regex=True).str.lower()\n",
    "print(f\"Initial columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "478b57b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "3. Data Type Conversions and Timestamp Creation\n",
      "=========================================================================================================\n",
      "Created 'ride_timestamp' column and dropped 'date' and 'time'.\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"3. Data Type Conversions and Timestamp Creation\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "try:\n",
    "    df['ride_timestamp'] = pd.to_datetime(df['date'] + ' ' + df['time'], errors='coerce')\n",
    "    # Drop the original separate columns\n",
    "    df = df.drop(columns=['date', 'time'])\n",
    "    print(\"Created 'ride_timestamp' column and dropped 'date' and 'time'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating ride_timestamp: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "92bffdc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "4. Categorical Cleanup and Standardization\n",
      "=========================================================================================================\n",
      "Standardized categorical columns (stripped whitespace and title-cased).\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"4. Categorical Cleanup and Standardization\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "# List of categorical columns to standardize\n",
    "categorical_cols = ['booking_id', 'booking_status', 'customer_id', 'vehicle_type', \n",
    "                    'pickup_location', 'drop_location', 'payment_method']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        # Strip leading/trailing whitespace and standardize casing\n",
    "        df[col] = df[col].astype(str).str.strip().str.title()\n",
    "        \n",
    "        # Specific cleanup for Booking ID which appears to have extra quotes in the snippet\n",
    "        if col == 'booking_id':\n",
    "            # Remove leading/trailing quotes that might have been missed by the parser\n",
    "            df[col] = df[col].str.replace('\"', '', regex=False).str.strip()\n",
    "\n",
    "print(\"Standardized categorical columns (stripped whitespace and title-cased).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfbde366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "5.Missing Numerical Value Imputation Based on Booking Status\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"5.Missing Numerical Value Imputation Based on Booking Status\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "# Define numerical columns that should be zero if the ride was not 'Completed'\n",
    "value_cols_to_impute = [\n",
    "    'avg_vtat', \n",
    "    'avg_ctat', \n",
    "    'booking_value', \n",
    "    'ride_distance', \n",
    "    'driver_ratings', \n",
    "    'customer_rating'\n",
    "]\n",
    "\n",
    "# Define columns related to cancellation/incompleteness that should be 0 instead of NaN/NULL\n",
    "flag_cols_to_zero = [\n",
    "    'cancelled_rides_by_customer',\n",
    "    'cancelled_rides_by_driver',\n",
    "    'incomplete_rides'\n",
    "]\n",
    "\n",
    "# A. Impute core metrics to 0 if the ride was not completed\n",
    "# 'No Driver Found', 'Cancelled', 'Incomplete' rides have no meaningful value, distance, or ratings.\n",
    "for col in value_cols_to_impute:\n",
    "    if col in df.columns:\n",
    "        # Check if the booking status is NOT 'Completed'\n",
    "        mask = df['booking_status'] != 'Completed'\n",
    "        # Fill NaN values in the specified column with 0 where the mask is True\n",
    "        df.loc[mask, col] = df.loc[mask, col].fillna(0)\n",
    "        # For the remaining NaNs (where status IS 'Completed'), we leave them as NaN \n",
    "        # as they represent genuinely missing data that may be imputed later (if needed) \n",
    "        # or handled by the BI tool.\n",
    "\n",
    "# B. Impute cancellation/incompletion flags to 0 where they are NaN\n",
    "for col in flag_cols_to_zero:\n",
    "    if col in df.columns:\n",
    "        # A NaN in these columns almost certainly means 'No' or 0 occurrences\n",
    "        df[col] = df[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f4b3a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "6. Final Data Type Enforcement\n",
      "=========================================================================================================\n",
      "Completed conditional imputation and final type enforcement.\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"6. Final Data Type Enforcement\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "# Convert imputed numerical columns to appropriate types\n",
    "for col in value_cols_to_impute + flag_cols_to_zero:\n",
    "    if col in df.columns:\n",
    "        # Use 'Int64' (Pandas integer with support for NaN) or standard float\n",
    "        if col in flag_cols_to_zero:\n",
    "            df[col] = df[col].astype('Int64') # Handles 1, 0, and NaNs if any remain\n",
    "        else:\n",
    "            df[col] = df[col].astype(float) # Ensure all other metrics are floats for precision\n",
    "\n",
    "print(\"Completed conditional imputation and final type enforcement.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a032e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "7. Summary and Output\n",
      "=========================================================================================================\n",
      "\n",
      "--- Cleaned DataFrame Summary ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 20 columns):\n",
      " #   Column                             Non-Null Count   Dtype         \n",
      "---  ------                             --------------   -----         \n",
      " 0   booking_id                         150000 non-null  object        \n",
      " 1   booking_status                     150000 non-null  object        \n",
      " 2   customer_id                        150000 non-null  object        \n",
      " 3   vehicle_type                       150000 non-null  object        \n",
      " 4   pickup_location                    150000 non-null  object        \n",
      " 5   drop_location                      150000 non-null  object        \n",
      " 6   avg_vtat                           150000 non-null  float64       \n",
      " 7   avg_ctat                           150000 non-null  float64       \n",
      " 8   cancelled_rides_by_customer        150000 non-null  Int64         \n",
      " 9   reason_for_cancelling_by_customer  10500 non-null   object        \n",
      " 10  cancelled_rides_by_driver          150000 non-null  Int64         \n",
      " 11  driver_cancellation_reason         27000 non-null   object        \n",
      " 12  incomplete_rides                   150000 non-null  Int64         \n",
      " 13  incomplete_rides_reason            9000 non-null    object        \n",
      " 14  booking_value                      150000 non-null  float64       \n",
      " 15  ride_distance                      150000 non-null  float64       \n",
      " 16  driver_ratings                     150000 non-null  float64       \n",
      " 17  customer_rating                    150000 non-null  float64       \n",
      " 18  payment_method                     150000 non-null  object        \n",
      " 19  ride_timestamp                     150000 non-null  datetime64[ns]\n",
      "dtypes: Int64(3), datetime64[ns](1), float64(6), object(10)\n",
      "memory usage: 23.3+ MB\n",
      "None\n",
      "\n",
      "--- Cleaned Data Head (First 5 Rows) ---\n",
      "   booking_id   booking_status   customer_id   vehicle_type  \\\n",
      "0  Cnr5884300  No Driver Found  \"Cid1982111\"          Ebike   \n",
      "1  Cnr1326809       Incomplete  \"Cid4604802\"       Go Sedan   \n",
      "2  Cnr8494506        Completed  \"Cid9202816\"           Auto   \n",
      "3  Cnr8906825        Completed  \"Cid2610914\"  Premier Sedan   \n",
      "4  Cnr1950162        Completed  \"Cid9933542\"           Bike   \n",
      "\n",
      "       pickup_location      drop_location  avg_vtat  avg_ctat  \\\n",
      "0          Palam Vihar            Jhilmil       0.0       0.0   \n",
      "1        Shastri Nagar  Gurgaon Sector 56       4.9      14.0   \n",
      "2              Khandsa      Malviya Nagar      13.4      25.8   \n",
      "3  Central Secretariat           Inderlok      13.1      28.5   \n",
      "4     Ghitorni Village        Khan Market       5.3      19.6   \n",
      "\n",
      "   cancelled_rides_by_customer reason_for_cancelling_by_customer  \\\n",
      "0                            0                               NaN   \n",
      "1                            0                               NaN   \n",
      "2                            0                               NaN   \n",
      "3                            0                               NaN   \n",
      "4                            0                               NaN   \n",
      "\n",
      "   cancelled_rides_by_driver driver_cancellation_reason  incomplete_rides  \\\n",
      "0                          0                        NaN                 0   \n",
      "1                          0                        NaN                 1   \n",
      "2                          0                        NaN                 0   \n",
      "3                          0                        NaN                 0   \n",
      "4                          0                        NaN                 0   \n",
      "\n",
      "  incomplete_rides_reason  booking_value  ride_distance  driver_ratings  \\\n",
      "0                     NaN            0.0           0.00             0.0   \n",
      "1       Vehicle Breakdown          237.0           5.73             0.0   \n",
      "2                     NaN          627.0          13.58             4.9   \n",
      "3                     NaN          416.0          34.02             4.6   \n",
      "4                     NaN          737.0          48.21             4.1   \n",
      "\n",
      "   customer_rating payment_method      ride_timestamp  \n",
      "0              0.0            Nan 2024-03-23 12:29:38  \n",
      "1              0.0            Upi 2024-11-29 18:01:39  \n",
      "2              4.9     Debit Card 2024-08-23 08:56:10  \n",
      "3              5.0            Upi 2024-10-21 17:17:25  \n",
      "4              4.3            Upi 2024-09-16 22:08:00  \n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"7. Summary and Output\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "print(\"\\n--- Cleaned DataFrame Summary ---\")\n",
    "print(df.info())\n",
    "print(\"\\n--- Cleaned Data Head (First 5 Rows) ---\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c863a6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "Creating new features based on existing data\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"=======\"*15)\n",
    "print(\"Creating new features based on existing data\")\n",
    "print(\"=======\"*15)\n",
    "print(\"=======\"*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7bbfd510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "PART-B 1. Load Data\n",
      "=========================================================================================================\n",
      "Successfully loaded ncr_ride_bookings.csv.\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"PART-B 1. Load Data\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "try:\n",
    "    # Use the filename provided in the context\n",
    "    df = pd.read_csv(\"ncr_ride_bookings.csv\", sep=',', quotechar='\"', engine='python')\n",
    "    print(\"Successfully loaded ncr_ride_bookings.csv.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'ncr_ride_bookings.csv' was not found.\")\n",
    "    df = pd.DataFrame()\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44bece05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "PART-B 2. Initial Column Name Cleanup (Required for consistency)\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"PART-B 2. Initial Column Name Cleanup (Required for consistency)\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '_').str.replace('[^A-Za-z0-9_]+', '', regex=True).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17d42354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "PART-B 3. Data Type Conversions and Timestamp Creation\n",
      "=========================================================================================================\n",
      "Error creating ride_timestamp: 'date'\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"PART-B 3. Data Type Conversions and Timestamp Creation\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "# Combine 'date' and 'time' into a single 'ride_timestamp' column\n",
    "try:\n",
    "    df['ride_timestamp'] = pd.to_datetime(df['date'] + ' ' + df['time'], errors='coerce')\n",
    "    df = df.drop(columns=['date', 'time'])\n",
    "except Exception as e:\n",
    "    print(f\"Error creating ride_timestamp: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e216ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "PART-B 4. Categorical Cleanup and Standardization\n",
      "=========================================================================================================\n",
      "Standardized categorical columns (stripped whitespace and title-cased).\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"PART-B 4. Categorical Cleanup and Standardization\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "categorical_cols = ['booking_id', 'booking_status', 'customer_id', 'vehicle_type', \n",
    "                    'pickup_location', 'drop_location', 'payment_method']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.title()\n",
    "        if col == 'booking_id':\n",
    "            df[col] = df[col].str.replace('\"', '', regex=False).str.strip()\n",
    "            \n",
    "print(\"Standardized categorical columns (stripped whitespace and title-cased).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e47b26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "PART-B 5. Missing Numerical Value Imputation (Replicating Cleaning Logic)\n",
      "=========================================================================================================\n",
      "Completed conditional imputation and final type enforcement.\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"PART-B 5. Missing Numerical Value Imputation (Replicating Cleaning Logic)\")\n",
    "print(\"=======\"*15)\n",
    "\n",
    "value_cols_to_impute = [\n",
    "    'avg_vtat', \n",
    "    'avg_ctat', \n",
    "    'booking_value', \n",
    "    'ride_distance', \n",
    "    'driver_ratings', \n",
    "    'customer_rating'\n",
    "]\n",
    "flag_cols_to_zero = [\n",
    "    'cancelled_rides_by_customer',\n",
    "    'cancelled_rides_by_driver',\n",
    "    'incomplete_rides'\n",
    "]\n",
    "\n",
    "# Impute core metrics to 0 if the ride was NOT 'Completed'\n",
    "mask_not_completed = df['booking_status'] != 'Completed'\n",
    "for col in value_cols_to_impute:\n",
    "    if col in df.columns:\n",
    "        df.loc[mask_not_completed, col] = df.loc[mask_not_completed, col].fillna(0)\n",
    "        df[col] = df[col].astype(float) # Final type enforcement\n",
    "\n",
    "# Impute cancellation/incompletion flags to 0 where they are NaN\n",
    "for col in flag_cols_to_zero:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype('Int64')\n",
    "        \n",
    "print(\"Completed conditional imputation and final type enforcement.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b658805e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating binary cancellation/incompletion flags...\n",
      "Calculating Price_Per_KM...\n",
      "Extracting time-based features...\n",
      "Calculating Efficiency_Ratio...\n",
      "Applying simple geospatial categorization...\n",
      "\n",
      "--- Feature Engineered DataFrame Summary ---\n",
      "Shape: (150000, 31)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150000 entries, 0 to 149999\n",
      "Data columns (total 31 columns):\n",
      " #   Column                             Non-Null Count   Dtype         \n",
      "---  ------                             --------------   -----         \n",
      " 0   booking_id                         150000 non-null  object        \n",
      " 1   booking_status                     150000 non-null  object        \n",
      " 2   customer_id                        150000 non-null  object        \n",
      " 3   vehicle_type                       150000 non-null  object        \n",
      " 4   pickup_location                    150000 non-null  object        \n",
      " 5   drop_location                      150000 non-null  object        \n",
      " 6   avg_vtat                           150000 non-null  float64       \n",
      " 7   avg_ctat                           150000 non-null  float64       \n",
      " 8   cancelled_rides_by_customer        150000 non-null  Int64         \n",
      " 9   reason_for_cancelling_by_customer  10500 non-null   object        \n",
      " 10  cancelled_rides_by_driver          150000 non-null  Int64         \n",
      " 11  driver_cancellation_reason         27000 non-null   object        \n",
      " 12  incomplete_rides                   150000 non-null  Int64         \n",
      " 13  incomplete_rides_reason            9000 non-null    object        \n",
      " 14  booking_value                      150000 non-null  float64       \n",
      " 15  ride_distance                      150000 non-null  float64       \n",
      " 16  driver_ratings                     150000 non-null  float64       \n",
      " 17  customer_rating                    150000 non-null  float64       \n",
      " 18  payment_method                     150000 non-null  object        \n",
      " 19  ride_timestamp                     150000 non-null  datetime64[ns]\n",
      " 20  is_cancelled_customer              150000 non-null  int64         \n",
      " 21  is_cancelled_driver                150000 non-null  int64         \n",
      " 22  is_incomplete                      150000 non-null  int64         \n",
      " 23  price_per_km                       102000 non-null  float64       \n",
      " 24  hour_of_day                        150000 non-null  int64         \n",
      " 25  day_of_week                        150000 non-null  object        \n",
      " 26  month_name                         150000 non-null  object        \n",
      " 27  is_peak_hour                       150000 non-null  int64         \n",
      " 28  efficiency_ratio                   102000 non-null  float64       \n",
      " 29  pickup_zone                        150000 non-null  object        \n",
      " 30  drop_zone                          150000 non-null  object        \n",
      "dtypes: Int64(3), datetime64[ns](1), float64(8), int64(5), object(14)\n",
      "memory usage: 35.9+ MB\n",
      "None\n",
      "\n",
      "--- Engineered Features Head (First 5 Rows) ---\n",
      "    booking_status  ride_distance  booking_value  price_per_km  is_peak_hour  \\\n",
      "0  No Driver Found           0.00            0.0           NaN             0   \n",
      "1       Incomplete           5.73          237.0     41.361257             1   \n",
      "2        Completed          13.58          627.0     46.170839             1   \n",
      "3        Completed          34.02          416.0     12.228101             1   \n",
      "4        Completed          48.21          737.0     15.287285             0   \n",
      "\n",
      "   efficiency_ratio     pickup_zone  is_cancelled_customer  \n",
      "0               NaN      West Delhi                      0  \n",
      "1          0.855148      West Delhi                      0  \n",
      "2          0.986745       South NCR                      0  \n",
      "3          0.385068  Other NCR Zone                      0  \n",
      "4          0.109936  Other NCR Zone                      0  \n"
     ]
    }
   ],
   "source": [
    "# 6.1. Cancellation/Incompletion Flags (Binary 1/0)\n",
    "print(\"Creating binary cancellation/incompletion flags...\")\n",
    "\n",
    "# Is_Cancelled_Customer: Based on 'cancelled_rides_by_customer' column > 0\n",
    "# CHANGED: Replaced 'Int64' with 'int'\n",
    "df['is_cancelled_customer'] = np.where(df['cancelled_rides_by_customer'] > 0, 1, 0).astype(int)\n",
    "\n",
    "# Is_Cancelled_Driver: Based on 'cancelled_rides_by_driver' column > 0\n",
    "# CHANGED: Replaced 'Int64' with 'int'\n",
    "df['is_cancelled_driver'] = np.where(df['cancelled_rides_by_driver'] > 0, 1, 0).astype(int)\n",
    "\n",
    "# Is_Incomplete: Based on 'incomplete_rides' column > 0 or booking_status is 'Incomplete'\n",
    "# CHANGED: Replaced 'Int64' with 'int'\n",
    "df['is_incomplete'] = np.where(\n",
    "    (df['incomplete_rides'] > 0) | (df['booking_status'] == 'Incomplete'), \n",
    "    1, \n",
    "    0\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# 6.2. Pricing Efficiency: Price_Per_KM (Booking Value / Ride Distance)\n",
    "print(\"Calculating Price_Per_KM...\")\n",
    "\n",
    "# Use numpy.where to avoid division by zero (where ride_distance is 0 or NaN)\n",
    "df['price_per_km'] = np.where(\n",
    "    (df['ride_distance'].fillna(0) > 0),\n",
    "    df['booking_value'] / df['ride_distance'],\n",
    "    np.nan # Use NaN for cases where distance is zero or missing\n",
    ").astype(float)\n",
    "\n",
    "\n",
    "# 6.3. Time Analysis Features\n",
    "print(\"Extracting time-based features...\")\n",
    "\n",
    "# Hour_of_Day\n",
    "# CHANGED: Replaced 'Int64' with 'int'\n",
    "df['hour_of_day'] = df['ride_timestamp'].dt.hour.astype(int)\n",
    "\n",
    "# Day_of_Week (0=Monday, 6=Sunday)\n",
    "df['day_of_week'] = df['ride_timestamp'].dt.day_name()\n",
    "\n",
    "# Month_Name\n",
    "df['month_name'] = df['ride_timestamp'].dt.month_name()\n",
    "\n",
    "# Is_Peak_Hour (7-10 AM and 5-8 PM)\n",
    "# CHANGED: Replaced 'Int64' with 'int'\n",
    "df['is_peak_hour'] = np.where(\n",
    "    ((df['hour_of_day'] >= 7) & (df['hour_of_day'] <= 9)) | \n",
    "    ((df['hour_of_day'] >= 17) & (df['hour_of_day'] <= 19)),\n",
    "    1,\n",
    "    0\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# 6.4. Performance Metrics: Efficiency_Ratio (Avg VTAT / Ride Distance)\n",
    "print(\"Calculating Efficiency_Ratio...\")\n",
    "\n",
    "# Measures how long it takes for a driver to reach a customer relative to the trip distance. Lower is better.\n",
    "# Handle division by zero/nulls for ride_distance\n",
    "df['efficiency_ratio'] = np.where(\n",
    "    (df['ride_distance'].fillna(0) > 0),\n",
    "    df['avg_vtat'] / df['ride_distance'],\n",
    "    np.nan\n",
    ").astype(float)\n",
    "\n",
    "\n",
    "# 6.5. Geospatial Categorization (Simple Logic for NCR Zones)\n",
    "print(\"Applying simple geospatial categorization...\")\n",
    "\n",
    "# Define simple lookups for common areas in NCR (New Delhi, Gurgaon, Noida)\n",
    "# This uses simple string checking on pickup_location/drop_location\n",
    "def classify_zone(location):\n",
    "    if pd.isna(location):\n",
    "        return 'Unknown'\n",
    "    location = str(location).upper()\n",
    "    \n",
    "    if 'GURGAON' in location or 'NEHRU PLACE' in location or 'MALVIYA NAGAR' in location or 'AYA NAGAR' in location or 'TUGHLAKABAD' in location or 'KHANDSA' in location:\n",
    "        return 'South NCR'\n",
    "    elif 'NOIDA' in location or 'AKSHARDHAM' in location or 'JHEL MIL' in location:\n",
    "        return 'East NCR'\n",
    "    elif 'KAROL BAGH' in location or 'JAMA MASJID' in location or 'VISHWAVIDYALAYA' in location:\n",
    "        return 'Central Delhi'\n",
    "    elif 'PALAM VIHAR' in location or 'SHASTRI NAGAR' in location:\n",
    "        return 'West Delhi'\n",
    "    else:\n",
    "        # Default to a general \"NCR\" or 'Other' zone\n",
    "        return 'Other NCR Zone'\n",
    "\n",
    "df['pickup_zone'] = df['pickup_location'].apply(classify_zone)\n",
    "df['drop_zone'] = df['drop_location'].apply(classify_zone)\n",
    "\n",
    "\n",
    "# --- 7. Final Summary and Output ---\n",
    "print(\"\\n--- Feature Engineered DataFrame Summary ---\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(df.info())\n",
    "print(\"\\n--- Engineered Features Head (First 5 Rows) ---\")\n",
    "print(df[['booking_status', 'ride_distance', 'booking_value', 'price_per_km', \n",
    "          'is_peak_hour', 'efficiency_ratio', 'pickup_zone', 'is_cancelled_customer']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6abe8c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: Cleaned and feature-engineered data saved to ncr_ride_bookings_processed.csv\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# --- 2. Save Processed Data to CSV Checkpoint ---\n",
    "# ====================================================================\n",
    "PROCESSED_FILENAME = 'ncr_ride_bookings_processed.csv'\n",
    "try:\n",
    "    df.to_csv(PROCESSED_FILENAME, index=False)\n",
    "    print(f\"\\nSUCCESS: Cleaned and feature-engineered data saved to {PROCESSED_FILENAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR saving CSV file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7c71c3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================================\n",
      "=========================================================================================================\n",
      "PART C SQL\n",
      "=========================================================================================================\n",
      "=========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=======\"*15)\n",
    "print(\"=======\"*15)\n",
    "print(\"PART C SQL\")\n",
    "print(\"=======\"*15)\n",
    "print(\"=======\"*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ee1713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded ncr_ride_bookings.csv.\n",
      "Starting data cleaning and standardization...\n",
      "Creating feature-rich columns...\n",
      "\n",
      "âœ… SUCCESS: Cleaned and feature-engineered data exported to ncr_ride_bookings_final_for_import.csv\n",
      "You can now import this file directly into MySQL Workbench.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Placeholder for the provided CSV file content\n",
    "try:\n",
    "    df = pd.read_csv(\"ncr_ride_bookings.csv\", sep=',', quotechar='\"', engine='python')\n",
    "    print(\"Successfully loaded ncr_ride_bookings.csv.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: The file 'ncr_ride_bookings.csv' was not found.\")\n",
    "    df = pd.DataFrame()\n",
    "    exit()\n",
    "\n",
    "# Initial Column Name Cleanup\n",
    "print(\"Starting data cleaning and standardization...\")\n",
    "df.columns = df.columns.str.replace(' ', '_').str.replace('[^A-Za-z0-9_]+', '', regex=True).str.lower()\n",
    "\n",
    "# Combine 'date' and 'time' into a single 'ride_timestamp' column\n",
    "try:\n",
    "    df['ride_timestamp'] = pd.to_datetime(df['date'] + ' ' + df['time'], errors='coerce')\n",
    "    df = df.drop(columns=['date', 'time'])\n",
    "except Exception as e:\n",
    "    print(f\"Error creating ride_timestamp: {e}\")\n",
    "\n",
    "# Categorical Cleanup and Standardization\n",
    "categorical_cols = ['booking_id', 'booking_status', 'customer_id', 'vehicle_type', \n",
    "                    'pickup_location', 'drop_location', 'payment_method']\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.title()\n",
    "        if col == 'booking_id':\n",
    "            # Remove any residual quotes from the ID field\n",
    "            df[col] = df[col].str.replace('\"', '', regex=False).str.strip()\n",
    "\n",
    "# Missing Numerical Value Imputation\n",
    "# Impute with 0 for non-completed rides, as these values (VTAT, distance, value) are irrelevant.\n",
    "value_cols_to_impute = [\n",
    "    'avg_vtat', 'avg_ctat', 'booking_value', 'ride_distance', \n",
    "    'driver_ratings', 'customer_rating'\n",
    "]\n",
    "\n",
    "mask_not_completed = df['booking_status'] != 'Completed'\n",
    "for col in value_cols_to_impute:\n",
    "    if col in df.columns:\n",
    "        df.loc[mask_not_completed, col] = df.loc[mask_not_completed, col].fillna(0)\n",
    "        df[col] = df[col].astype(float)\n",
    "\n",
    "# Impute flag columns\n",
    "flag_cols_to_zero = [\n",
    "    'cancelled_rides_by_customer', 'cancelled_rides_by_driver', 'incomplete_rides'\n",
    "]\n",
    "\n",
    "for col in flag_cols_to_zero:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna(0).astype(int) \n",
    "\n",
    "# --- Feature Engineering ---\n",
    "print(\"Creating feature-rich columns...\")\n",
    "\n",
    "# Cancellation/Incompletion Flags\n",
    "df['is_cancelled_customer'] = np.where(df['cancelled_rides_by_customer'] > 0, 1, 0).astype(int)\n",
    "df['is_cancelled_driver'] = np.where(df['cancelled_rides_by_driver'] > 0, 1, 0).astype(int)\n",
    "\n",
    "# *** IMPORTANT FIX: Rename 'is_incomplete' to 'trip_incomplete' to match SQL schema ***\n",
    "df['trip_incomplete'] = np.where(\n",
    "    (df['incomplete_rides'] > 0) | (df['booking_status'] == 'Incomplete'), \n",
    "    1, \n",
    "    0\n",
    ").astype(int)\n",
    "# df['is_incomplete'] column is implicitly replaced by df['trip_incomplete'] above\n",
    "# Original definition:\n",
    "# df['is_incomplete'] = np.where(\n",
    "#     (df['incomplete_rides'] > 0) | (df['booking_status'] == 'Incomplete'), \n",
    "#     1, \n",
    "#     0\n",
    "# ).astype(int)\n",
    "\n",
    "\n",
    "# Pricing Efficiency: Price_Per_KM\n",
    "df['price_per_km'] = np.where(\n",
    "    (df['ride_distance'].fillna(0) > 0),\n",
    "    df['booking_value'] / df['ride_distance'],\n",
    "    np.nan\n",
    ").astype(float)\n",
    "\n",
    "# Time Analysis Features\n",
    "df['hour_of_day'] = df['ride_timestamp'].dt.hour.astype(int)\n",
    "df['day_of_week'] = df['ride_timestamp'].dt.day_name()\n",
    "df['month_name'] = df['ride_timestamp'].dt.month_name()\n",
    "df['is_peak_hour'] = np.where(\n",
    "    ((df['hour_of_day'] >= 7) & (df['hour_of_day'] <= 9)) | \n",
    "    ((df['hour_of_day'] >= 17) & (df['hour_of_day'] <= 19)),\n",
    "    1,\n",
    "    0\n",
    ").astype(int)\n",
    "\n",
    "# Performance Metrics: Efficiency_Ratio (VTAT per KM)\n",
    "df['efficiency_ratio'] = np.where(\n",
    "    (df['ride_distance'].fillna(0) > 0),\n",
    "    df['avg_vtat'] / df['ride_distance'],\n",
    "    np.nan\n",
    ").astype(float)\n",
    "\n",
    "# Geospatial Categorization\n",
    "def classify_zone(location):\n",
    "    if pd.isna(location): return 'Unknown'\n",
    "    location = str(location).upper()\n",
    "    \n",
    "    if 'GURGAON' in location or 'NEHRU PLACE' in location or 'MALVIYA NAGAR' in location or 'AYA NAGAR' in location or 'TUGHLAKABAD' in location or 'KHANDSA' in location:\n",
    "        return 'South NCR'\n",
    "    elif 'NOIDA' in location or 'AKSHARDHAM' in location or 'JHEL MIL' in location:\n",
    "        return 'East NCR'\n",
    "    elif 'KAROL BAGH' in location or 'JAMA MASJID' in location or 'VISHWAVIDYALAYA' in location:\n",
    "        return 'Central Delhi'\n",
    "    elif 'PALAM VIHAR' in location or 'SHASTRI NAGAR' in location:\n",
    "        return 'West Delhi'\n",
    "    else:\n",
    "        return 'Other NCR Zone'\n",
    "\n",
    "df['pickup_zone'] = df['pickup_location'].apply(classify_zone)\n",
    "df['drop_zone'] = df['drop_location'].apply(classify_zone)\n",
    "\n",
    "\n",
    "# --- Final Export to CSV ---\n",
    "PROCESSED_FILENAME = 'ncr_ride_bookings_final_for_import.csv'\n",
    "# Rename columns to match the SQL schema's expected casing/naming conventions for the wizard\n",
    "# The SQL schema uses TitleCase/PascalCase for column names\n",
    "column_mapping = {\n",
    "    'ride_timestamp': 'Ride_Timestamp',\n",
    "    'hour_of_day': 'Hour_of_Day',\n",
    "    'day_of_week': 'Day_of_Week',\n",
    "    'month_name': 'Month_Name',\n",
    "    'is_peak_hour': 'Is_Peak_Hour',\n",
    "    'booking_id': 'Booking_ID',\n",
    "    'booking_status': 'Booking_Status',\n",
    "    'customer_id': 'Customer_ID',\n",
    "    'vehicle_type': 'Vehicle_Type',\n",
    "    'payment_method': 'Payment_Method',\n",
    "    'pickup_location': 'Pickup_Location',\n",
    "    'drop_location': 'Drop_Location',\n",
    "    'pickup_zone': 'Pickup_Zone',\n",
    "    'drop_zone': 'Drop_Zone',\n",
    "    'avg_vtat': 'Avg_VTAT',\n",
    "    'avg_ctat': 'Avg_CTAT',\n",
    "    'driver_ratings': 'Driver_Ratings',\n",
    "    'customer_rating': 'Customer_Rating',\n",
    "    'booking_value': 'Booking_Value',\n",
    "    'ride_distance': 'Ride_Distance',\n",
    "    'price_per_km': 'Price_Per_KM',\n",
    "    'efficiency_ratio': 'Efficiency_Ratio',\n",
    "    'is_cancelled_customer': 'Is_Cancelled_Customer',\n",
    "    'is_cancelled_driver': 'Is_Cancelled_Driver',\n",
    "    # Ensure this matches the renamed column in the SQL schema\n",
    "    'trip_incomplete': 'Trip_Incomplete', \n",
    "    'cancelled_rides_by_customer': 'Cancelled_Rides_By_Customer',\n",
    "    'cancelled_rides_by_driver': 'Cancelled_Rides_By_Driver',\n",
    "    'incomplete_rides': 'Incomplete_Rides',\n",
    "    'reason_for_cancelling_by_customer': 'Reason_For_Cancelling_By_Customer',\n",
    "    'driver_cancellation_reason': 'Driver_Cancellation_Reason',\n",
    "    'incomplete_rides_reason': 'Incomplete_Rides_Reason'\n",
    "}\n",
    "\n",
    "# Apply renames before saving the CSV\n",
    "df = df.rename(columns=column_mapping)\n",
    "\n",
    "# Drop any columns that were in the original CSV but not defined in the SQL mapping\n",
    "# (e.g., the original date/time columns if they were not explicitly dropped earlier)\n",
    "# This step is often necessary for clean SQL import.\n",
    "columns_to_keep = list(column_mapping.values())\n",
    "df = df.reindex(columns=columns_to_keep, fill_value=None)\n",
    "\n",
    "\n",
    "try:\n",
    "    df.to_csv(PROCESSED_FILENAME, index=False, na_rep='NULL')\n",
    "    print(f\"\\nâœ… SUCCESS: Cleaned and feature-engineered data exported to {PROCESSED_FILENAME}\")\n",
    "    print(\"You can now import this file directly into MySQL Workbench.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ERROR saving CSV file: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
